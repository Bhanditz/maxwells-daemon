@article{bengio2000gradient,
  title={Gradient-based optimization of hyperparameters},
  author={Bengio, Yoshua},
  journal={Neural computation},
  volume={12},
  number={8},
  pages={1889--1900},
  year={2000},
  publisher={MIT Press}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@Article{lecun1989backpropagation,
	title = "Backpropagation applied to handwritten zip code recognition",
	author = "Y. LeCun and B. Boser and J. S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jackel",
	journal = "Neural Computation",
	volume = "1",
	pages = "541--551",
	year = "1989",
	publisher = "Massachusetts Institute of Technology"
}

@inproceedings{snoek2012practical,
  title={Practical {B}ayesian Optimization of Machine Learning Algorithms},
  author={Snoek, Jasper and Larochelle, Hugo and Ryan P. Adams},
  booktitle={Advances in Neural Information Processing Systems 25},
  pages={2960--2968},
  year={2012}
}

@Article{ salakhutdinov2008using,
	author = "Ruslan Salakhutdinov and Geoffrey Hinton",
	title = "Using Deep Belief Nets to Learn Covariance Kernels for {G}aussian Processes",
	journal = "Advances in Neural information processing systems",
	volume = "20",
	pages = "1249--1256",
	year = "2008",
	booktitle = "Advances in Neural Information Processing Systems"
}

@Book{ rasmussen38gaussian,
	author = "Carl E. Rasmussen and Christopher K.I. Williams",
	title = "{G}aussian Processes for Machine Learning",
	publisher = "The MIT Press, Cambridge, MA, USA",
	year = "2006"
}

@Article{ bengio1994learning,
	title = "Learning long-term dependencies with gradient descent is difficult",
	author = "Yoshua Bengio and Patrice Simard and Paolo Frasconi",
	journal = "Neural Networks, IEEE Transactions on",
	volume = "5",
	number = "2",
	pages = "157--166",
	year = "1994",
	publisher = "IEEE"
}

@Article{ pascanu2012understanding,
	title = "Understanding the exploding gradient problem",
	author = "Razvan Pascanu and Tomas Mikolov and Yoshua Bengio",
	journal = "arXiv preprint arXiv:1211.5063",
	year = "2012"
}

@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  year={1995},
  publisher={MIT Press}
}

@article{chapelle2002choosing,
  title={Choosing multiple parameters for support vector machines},
  author={Chapelle, Olivier and Vapnik, Vladimir and Bousquet, Olivier and Mukherjee, Sayan},
  journal={Machine learning},
  volume={46},
  number={1-3},
  pages={131--159},
  year={2002},
  publisher={Springer}
}

@incollection{larsen1998adaptive,
  title={Adaptive regularization in neural network modeling},
  author={Larsen, Jan and Svarer, Claus and Andersen, Lars Nonboe and Hansen, Lars Kai},
  booktitle={Neural Networks: Tricks of the Trade},
  pages={113--132},
  year={1998},
  publisher={Springer}
}

@article{deepGPVar14,
title={Nested Variational Compression in Deep {G}aussian Processes},
author={James Hensman and Neil D. Lawrence},
journal={arXiv preprint arXiv:1412.1370},
year={2014}}

@article{schaul2012no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  journal={arXiv preprint arXiv:1206.1106},
  year={2012}}

@article{Adam14,
title={Adam: A Method for Stochastic Optimization},
author={Diederik Kingma and Jimmy Ba},
journal={arXiv preprint arXiv:1412.6980},
year={2014}}

@article{Adasecant14,
title={{ADASECANT}: Robust Adaptive Secant Method for Stochastic Gradient},
author={Caglar Gulcehre and Yoshua Bengio},
journal={arXiv preprint arXiv:1412.7419},
year={2014}}

@article{Hotswap14,
title={Hot Swapping for Online Adaptation of Optimization Hyperparameters},
author={Kevin Bache and Dennis DeCoste and Padhraic Smyth},
journal={arXiv preprint arXiv:1412.6599},
year={2014}}

@article{Bridging14,
title={{M}arkov Chain {M}onte {C}arlo and Variational Inference: Bridging the Gap},
author={Tim Salimans and Diederik P. Kingma and Max Welling},
journal={arXiv preprint arXiv:1410.6460},
year={2014}}

@inproceedings{Autodiff14,
title={Automatic differentiation of algorithms for machine learning},
author={Baydin, A. G. and Pearlmutter, B. A.},
booktitle={Proceedings of the AutoML Workshop at the International Conference on Machine Learning (ICML)},
year={2014}}

@phdthesis{pearlmutter1996investigation,
  title={An investigation of the gradient descent process in neural networks},
  author={Pearlmutter, Barak},
  school = {Carnegie Mellon University},
  year={1996}
}

@phdthesis{samuel2012gradient,
  title={Gradient based {MRF} learning for image restoration and segmentation},
  author={Samuel, Kegan G.},
  year={2012},
  school={University of Central Florida Orlando, Florida}
}

@inproceedings{bergstra2011algorithms,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2011}
}

@inproceedings{BerYamCox13,
    Title={Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures},
    Author={James Bergstra and Daniel Yamins and David Cox},
    Pages={115--123},
    Year={2013},
    Booktitle = {International Conference on Machine Learning}
}

@InProceedings{HutHooLey11,
  author= {Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
  title = {Sequential Model-Based Optimization for General Algorithm Configuration},
  booktitle = {Proceedings of LION-5},
  publisher = {Springer},
  year = {2011},
  pages = {507--523},
  volume={6683}
}

@article{pearlmutter2009sleep,
  title={A new hypothesis for sleep: tuning for criticality},
  author={Pearlmutter, Barak A and Houghton, Conor J},
  journal={Neural computation},
  volume={21},
  number={6},
  pages={1622--1641},
  year={2009}, 
  publisher={MIT Press}
}

@MISC{Bastien-Theano-2012,
        author = {Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian J. and Bergeron, Arnaud and Bouchard, Nicolas and Bengio, Yoshua},
         title = {Theano: new features and speed improvements},
          year = {2012},
  howpublished = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop}}
}

@INPROCEEDINGS{bergstra2010scipy,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation}}
}

@article{pearlmutter2008reverse,
  title={Reverse-mode {AD} in a functional framework: Lambda the ultimate backpropagator},
  author={Pearlmutter, Barak A. and Siskind, Jeffrey Mark},
  journal={ACM Transactions on Programming Languages and Systems (TOPLAS)},
  volume={30},
  number={2},
  pages={7},
  year={2008},
  publisher={ACM}
}

@article{solak2003derivative,
  title={Derivative observations in {G}aussian process models of dynamic systems},
  author={Solak, E. and Murray Smith, R. and Leithead, W.E. and Leith, D. and Rasmussen, Carl E.},
  journal={Advances in Neural Information Processing Systems},
  pages={1057--1064},
  year={2003},
  publisher={MIT Press}
}

@incollection{sequence2014,
title = {Sequence to Sequence Learning with Neural Networks},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V. V},
booktitle = {Advances in Neural Information Processing Systems 27},
pages = {3104--3112},
year = {2014},
publisher = {Curran Associates, Inc.}
}

@article{oliphant2007python,
  title={Python for scientific computing},
  author={Oliphant, Travis E},
  journal={Computing in Science \& Engineering},
  volume={9},
  number={3},
  pages={10--20},
  year={2007},
  publisher={AIP Publishing}
}

@ARTICLE{leapfrog1995,
   author = {{Hut}, P. and {Makino}, J. and {McMillan}, S.},
    title = "{Building a better leapfrog}",
  journal = {Astrophysical Journal, Part 2 - Letters},
     year = 1995,
    month = apr,
   volume = 443,
    pages = {L93-L96},
      doi = {10.1086/187844}
}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the {H}essian},
  author={Pearlmutter, Barak A.},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}

@phdthesis{steinruecken2014a,
    title = {Lossless Data Compression},
    author = {Christian Steinruecken},
    school = {{University of Cambridge}},
    year = {2014}
}


@article{dahl2014multi,
  title={Multi-task Neural Networks for {QSAR} Predictions},
  author={Dahl, George E and Jaitly, Navdeep and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1406.1231},
  year={2014}
}

@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
  pages={1139--1147},
  year={2013}
}

@article{graves2014neural,
  title={Neural Turing Machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  year={2014}
}

@article{laloudouana2003data,
  title={Data set selection},
  author={LaLoudouana, Doudou and Tarare, Mambobo Bonouliqui},
  journal={Journal of Machine Learning Gossip},
  volume={1},
  pages={11--19},
  year={2003},
  publisher={Citeseer}
}

@article{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={625--660},
  year={2010},
  publisher={JMLR}
}

@misc{Tieleman2012,
  title={{Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude}},
  author={Tieleman, T. and Hinton, G.},
  howpublished={Coursera: Neural Networks for Machine Learning},
  year={2012}
}

@incollection{martens2012training,
  title={Training deep and recurrent networks with hessian-free optimization},
  author={Martens, James and Sutskever, Ilya},
  booktitle={Neural Networks: Tricks of the Trade},
  pages={479--535},
  year={2012},
  publisher={Springer}
}

@article{courbariaux2014low,
  title={Low precision arithmetic for deep learning},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  journal={arXiv preprint arXiv:1412.7024},
  year={2014}
}

@phdthesis{omniglot,
    title = {Towards more human-like concept learning in machines: Compositionality, causality, and
learning-to-learn},
    author = {Brenden M. Lake},
    school = {{Massachusetts Institute of Technology}},
    year = {2014}
}

@incollection{mackay1994automatic,
  title={Automatic relevance determination for neural networks},
  author={MacKay, David J.C. and Neal, Radford M.},
  booktitle={Technical Report},
  year={1994},
  publisher={Cambridge University}
}

@inproceedings{domke2012generic,
  title={Generic methods for optimization-based modeling},
  author={Domke, Justin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={318--326},
  year={2012}
}

@inproceedings{foo2008efficient,
  title={Efficient multiple hyperparameter learning for log-linear models},
  author={Foo, Chuan-sheng and Do, Chuong B. and Ng, Andrew Y.},
  booktitle={Advances in neural information processing systems},
  pages={377--384},
  year={2008}
}

@inproceedings{chen1999optimal,
  title={Optimal use of regularization and cross-validation in neural network modeling},
  author={Chen, Dingding and Hagan, Martin T.},
  booktitle={International Joint Conference on Neural Networks},
  volume={2},
  pages={1275--1280},
  year={1999},
  organization={IEEE}
}

@inproceedings{eigenmann1999gradient,
  title={Gradient based adaptive regularization},
  author={Eigenmann, Robert and Nossek, Josef A.},
  booktitle={Proceedings of the 1999 IEEE Signal Processing Society Workshop on Neural Networks},
  pages={87--94},
  year={1999},
  organization={IEEE}
}

@inproceedings{goutte1998adaptive,
  title={Adaptive regularization of neural networks using conjugate gradient},
  author={Goutte, Cyril and Larsen, Jan},
  booktitle={IEEE 1998 International Conference on Acoustics, Speech, and Signal Processing},
  year={1998},
  pages={1201--1204}
}

@techreport{abdel2007adaptive,
  title={Adaptive optimization of hyperparameters in {L2}-regularised logistic regression},
  author={Abdel-Gawad, Ahmed and Ratner, Simon},
  year={2007}
}

@inproceedings{alp2014blackbox,
  title={Fully Automatic Variational Inference of Differentiable Probability Models},
  author={Alp Kucukelbir and Rajesh Ranganath and Andrew Gelman and David Blei},
  booktitle={NIPS Workshop on Probabilistic Programming},
  year={2014}
}


@article{courbariaux2014low,
  title={{RMS}Prop and equilibrated adaptive learning rates for non-convex optimization},
  author={Yann N. Dauphin and Harm de Vries and Junyoung Chung and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1502.04390},
  year={2015}
}

@inproceedings{ma2013estimating,
  title={Estimating the partition function of graphical models using Langevin importance sampling},
  author={Ma, Jianzhu and Peng, Jian and Wang, Sheng and Xu, Jinbo},
  booktitle={Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
  pages={433--441},
  year={2013}
}

@article{sohl2012hamiltonian,
  title={Hamiltonian annealed importance sampling for partition function estimation},
  author={Sohl-Dickstein, Jascha and Culpepper, Benjamin J},
  journal={arXiv preprint arXiv:1205.1925},
  year={2012}
}


@article{sohl2014hamiltonian,
  title={{H}amiltonian {M}onte {C}arlo without detailed balance},
  author={Sohl-Dickstein, Jascha and Mudigonda, Mayur and DeWeese, Michael R},
  journal={arXiv preprint arXiv:1409.5191},
  year={2014}
}

@article{betancourt2015fundamental,
  title={The Fundamental Incompatibility of {H}amiltonian {M}onte {C}arlo and Data Subsampling},
  author={Betancourt, Michael. J.},
  journal={arXiv preprint arXiv:1502.01510},
  year={2015}
}

@article{vollmer2015non,
  title={(Non-) asymptotic properties of Stochastic Gradient Langevin Dynamics},
  author={Vollmer, Sebastian J. and Zygalakis, Konstantinos C. and others},
  journal={arXiv preprint arXiv:1501.00438},
  year={2015}
}


@inproceedings{kingma2014efficient,
  title={Efficient Gradient-Based Inference through Transformations between Bayes Nets and Neural Nets},
  author={Kingma, Diederik and Welling, Max},
  booktitle={Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
  pages={1782--1790},
  year={2014}
}

@inproceedings{icml2014c2_ahn14, 
    Title = {Distributed Stochastic Gradient {MCMC},
    Url = {http://jmlr.org/proceedings/papers/v32/ahn14.pdf}, 
    Abstract = {Probabilistic inference on a big data scale is becoming increasingly relevant to both the machine learning and statistics communities. Here we introduce the first fully distributed MCMC algorithm based on stochastic gradients. We argue that stochastic gradient MCMC algorithms are particularly suited for distributed inference because individual chains can draw minibatches from their local pool of data for a flexible amount of time before jumping to or syncing with other chains. This greatly reduces communication overhead and allows adaptive load balancing. Our experiments for LDA on Wikipedia and Pubmed show that relative to the state of the art in distributed MCMC we reduce compute time from 27 hours to half an hour in order to reach the same perplexity level.}, 
    Author = {Sungjin Ahn and Babak Shahbaba and Max Welling}, 
    Year = {2014}, 
    Booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)}, 
    Pages = {1044-1052} 
   }

@inproceedings{welling2011bayesian,
  title={{B}ayesian learning via stochastic gradient {L}angevin dynamics},
  author={Welling, Max and Teh, Yee Whye},
  booktitle={Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@article{MacDuvAda2015hyper,
  title={Gradient-based Hyperparameter Optimization through Reversible Learning},
  author={Dougal Maclaurin and David Duvenaud and Ryan P. Adams},
  journal={Arxiv preprint arXiv:1502.03492},
  year={2015}
}

@article{wainwright2008graphical,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael I},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume=1,
  number={1-2},
  pages={1--305},
  year=2008,
  publisher={Now Publishers Inc.}
}

@article{mackay1992practical,
  title={A practical Bayesian framework for backpropagation networks},
  author={MacKay, David JC},
  journal={Neural computation},
  volume={4},
  number={3},
  pages={448--472},
  year={1992},
  publisher={MIT Press}
}

@article{bai1996some,
  title={Some large-scale matrix computation problems},
  author={Bai, Zhaojun and Fahey, Gark and Golub, Gene},
  journal={Journal of Computational and Applied Mathematics},
  volume={74},
  number={1},
  pages={71--89},
  year={1996},
  publisher={Elsevier}
}

@article{raskutti2014early,
  title={Early stopping and non-parametric regression: an optimal data-dependent stopping rule},
  author={Raskutti, Garvesh and Wainwright, Martin J. and Yu, Bin},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={335--366},
  year={2014}
}

@article{neal2011mcmc,
  title={MCMC using Hamiltonian dynamics},
  author={Neal, Radford M},
  journal={Handbook of Markov Chain Monte Carlo},
  volume={2},
  year={2011}
}

@article{stein1981estimation,
  title={Estimation of the Mean of a Multivariate Normal Distribution},
  author={Stein, Charles M},
  journal={The Annals of Statistics},
  volume={9},
  number={6},
  pages={1135--1151},
  year={1981}
}
